-- Asteroid implementation of a simple calculator language
-- The interpreter will read an expression from stdin and output is
-- written to stdout.  The program
--   (2+3)*2
-- will print the value 10.  In order to terminate interactively
-- provided input you will have to type <CR><Cntrl-D>
-- Lutz Hamel, (c) University of Rhode Island

load system io.
load tokenizer.
load lexer.

-------------------------------------------------------------------------
-- A recursive descent parser implementing the following grammar:
-- <expression> ::= <mulexp> { ('+' <mulexp>) | ('-' <mulexp>) }
-- <mulexp>     ::= <rootexp> { ('*' <rootexp>) | ('/' <rootexp>) }
-- <rootexp>    ::= number | '-' <rootexp> | '(' <expression> ')'
-- The parser implements arithmetic on integer values

function expression
  with lex do
    let val = mulexp(lex).
    loop do
      let token = lex @peek().
      if isnone token do
        break.
      elif token @type == "add" do
        lex @token_match("add").
        let val = val + mulexp(lex).
      elif token @type == "sub" do
        lex @token_match("sub").
        let val = val - mulexp(lex)
      else do
        break.
      end
    end
    return val.
end

function mulexp
  with lexer do
    let val = rootexp(lexer).
    if isnone (lexer @peek()) do
      return val.
    end
    loop do
      let token = lexer @peek().
      if isnone token do
        break.
      elif token @type == "mul" do
        lexer @token_match("mul").
        let val = val * rootexp(lexer).
      elif token @type == "div" do
        lexer @token_match("div").
        let val = val / rootexp(lexer)
      else do
        break.
      end
    end
    return val.
end

function rootexp
  with lexer do
    let tokenizer @Token(type,val) = lexer @peek().
    if type == "number" do
      lexer @token_match("number").
      return val.
    elif type == "sub" do
      lexer @token_match("sub").
      return - rootexp(lexer).
    elif type == "lparen" do
      lexer @token_match("lparen").
      let val = expression(lexer).
      lexer @token_match("rparen").
      return val.
    else do
      throw Error("syntax error at token "+val).
    end
end

-------------------------------------------------------------------------
-- driver part of the script
if toplevel () do
  -- tokenize input
  let input = io @read().
  let lexer = lexer @Lexer input.
  #println lexer.

  -- parse and interpret input
  let val = expression(lexer).
    io @println val.
  if not (lexer @eof()) do
    throw Error("tokens still in input stream")
  end

  -- print out the final value of the parsed and interpreted expression
  io @println val.
end
