-- a convenient interface to a token stream produced by the
-- tokenize function.
-- Lutz Hamel, (c) University of Rhode Island

load tokenizer.

structure Lexer with
  data token_stream.

  function __init__ with input:%string do
    let this@token_stream = tokenizer @tokenize input.
  end

  function get
    with none do
      return this @token_stream @get().
  end

  function peek
    with none do
      return this @token_stream @peek().
  end

  function eof
    with none do
      return this @token_stream @eof().
  end

  function token_match
    with token_type do
      let token = this @token_stream @peek().
      if token @type == token_type do
        this @token_stream @get().
      else do
        throw Error("expected token "+token_type+" got "+token @type).
      end
  end

end -- structure

if toplevel() do
  load system io.
  let lex = Lexer("1+1").
  io @println (lex @token_stream).
end
